{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"./images/DLI_Header.png\"></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Content-Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Content-based filtering](http://recommender-systems.org/content-based-filtering/) is a simple and effective way to recommend items based on a single user's previous feedback. It works by comparing the categories of an item, such as genres for movies or properties of clothing.\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates:\n",
    "* How to build a content-based filter\n",
    "  * [1. A Sweet Example](#1.-A-Sweet-Example)\n",
    "  * [2. Building a Content-Based Filter](#2.-Building-a-Content-Based-Filter)\n",
    "* How to use a content-based filter for recommendation\n",
    "  * [3. Making Predictions](#3.-Making-Predictions)\n",
    "  * [4. Wrap Up](#4.-Wrap-Up)\n",
    "\n",
    "## 1. A Sweet Example\n",
    "\n",
    "Let's look at a toy example with candies. The example below is what's called a user-item interaction matrix, where rows represent users, columns represent items, and the cells represent how the respective user interacted with the respective item. In this case, the users have scored the candies they've tried on a 1 star to 5 star scale. Dashes, `-`, represent items they haven't had yet.\n",
    "\n",
    "User | M&Ms | Skittles | Snickers | Laffy Taffy | Caramel Chew\n",
    "-|-|-|-|-|-\n",
    "Lara| 3 | - | 5 | - | -\n",
    "Daisy| 4 | - | - | 1 | -\n",
    "Alyx | - | - | - | - | 5\n",
    "Sarah | - | 3 | 2 | - | -\n",
    "\n",
    "Let's say we consult our subject matter experts to categorize and label these candies. They might give us another table that looks like this:\n",
    "\n",
    "Candy | Chocolate | Round | Colorful | Fruity | Caramel | Chewy\n",
    "- | - | - | - | - | - | -\n",
    "M&Ms | 1 | 1 | 1 | 0 | 0 | 0\n",
    "Skittles | 0 | 1 | 1 | 1 | 0 | 0\n",
    "Snickers | 1 | 0 | 0 | 0 | 1 | 0\n",
    "Laffy Taffy | 0 | 0 | 1 | 1 | 0 | 1\n",
    "Caramel Chew | 0 | 0 | 0 | 0 | 1 | 1 |\n",
    "\n",
    "There are many ways to build a content-based filter, but one quick and effective way is by finding the user's percent preference per category.\n",
    "\n",
    "## 2. Building a Content-Based Filter\n",
    "\n",
    "<img src=\"images/bayesian.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "Let's start by loading our toy problem into a CUDA Data Frame using [cuDF](https://docs.rapids.ai/api/cudf/stable/), which is a drop-in replacement library for pandas that executes on the GPU as opposed to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "ratings = cudf.DataFrame({\n",
    "    'user': [\"Lara\", \"Lara\", \"Daisy\", \"Daisy\", \"Alyx\", \"Sarah\", \"Sarah\"],\n",
    "    'item': [\"m_ms\", \"snickers\", \"m_ms\", \"laffy_taffy\", \"caramel_chew\", \"skittles\", \"snickers\"],\n",
    "    'rating': [3, 5, 4, 1, 5, 3, 2]})\n",
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = cudf.DataFrame({\n",
    "    'item': [\"m_ms\", \"skittles\", \"snickers\", \"laffy_taffy\", \"caramel_chew\"],\n",
    "    'chocolate': [1, 0, 1, 0, 0],\n",
    "    'round': [1, 1, 0, 0, 0],\n",
    "    'colorful': [1, 1, 0, 1, 0],\n",
    "    'fruity': [0, 1, 0, 1, 0],\n",
    "    'caramel': [0, 0, 1, 0, 1],\n",
    "    'chewy': [0, 0, 1, 1, 1]})\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join these DataFrames with [merge](https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.merge.html) so we can find each user's preference for a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_ratings = ratings.merge(categories, on=\"item\", how=\"left\")\n",
    "\n",
    "joined_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a Content-Based Filter, we'll start by multiplying each user's rating by the category for the item that rating belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candy_classes = ['chocolate', 'round', 'colorful', 'fruity', 'caramel', 'chewy']\n",
    "\n",
    "for candy_class in candy_classes:\n",
    "    joined_ratings[candy_class] = (\n",
    "        joined_ratings[candy_class] * joined_ratings[\"rating\"])\n",
    "\n",
    "joined_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use [groupby](https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.groupby.html) to sum the columns for each user to find the total number of points given to each category. We can also drop the `rating` column as we won't need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profiles = joined_ratings.drop(\"rating\", axis=1)\n",
    "user_profiles = user_profiles.groupby(['user']).sum()\n",
    "\n",
    "user_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this filtering method is to find the user's percent preference for each category, so for that, we'll need the total amount of points given across every category for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profiles[\"total\"] = user_profiles[candy_classes].sum(axis=1)\n",
    "\n",
    "user_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can divide each category by the total to get a user's percentage preference for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candy_class in candy_classes:\n",
    "    user_profiles[candy_class] = (\n",
    "        user_profiles[candy_class] / user_profiles[\"total\"])\n",
    "    \n",
    "user_profiles = user_profiles.drop(\"total\", axis=1)\n",
    "\n",
    "user_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Making Predictions\n",
    "\n",
    "We can use these percentages to make new recommendations. For instance, Alyx has only had one candy: Caramel Chews. We can multiply her user profile across an item's categories to see what her predicted rating would be for that item.\n",
    "\n",
    "With [CuPy](https://cupy.chainer.org/), we can efficiently do this for all users at once! CuPy is a GPU array library inspired by [NumPy](https://numpy.org/). Let's convert our DataFrames to CuPy arrays following the [conversion guide](https://docs.rapids.ai/api/cudf/stable/user_guide/10min-cudf-cupy.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "user_profiles_cupy = cp.fromDlpack(user_profiles.to_dlpack())\n",
    "\n",
    "user_profiles_cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_cupy = cp.fromDlpack(categories.drop(\"item\", axis=1).to_dlpack())\n",
    "\n",
    "categories_cupy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a prediction for one user first. We can take Alyx's profile and multiply it with the categories for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alyx_ratings = user_profiles_cupy[0] * categories_cupy\n",
    "\n",
    "alyx_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can [sum](https://docs-cupy.chainer.org/en/stable/reference/generated/cupy.sum.html) each row to see the predicted preference for that corresponding row's item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alyx_ratings = cp.sum(alyx_ratings, axis=1)\n",
    "\n",
    "alyx_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Alyx would get a high rating for Snickers and Caramel Chews, but low ratings for M&Ms and Skittles.\n",
    "\n",
    "Now, let's do this for everyone. We can be efficient with our data by using [NumPy](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) broadcasting rules.\n",
    "\n",
    "`user_profiles_cupy` and `categories_cupy` are 4x6 and 5x6 respectively. If we try to multiply them without doing anything, CuPy will give us a dimension mismatch error. We can use [cupy.expand_dims](https://docs-cupy.chainer.org/en/stable/reference/generated/cupy.expand_dims.html) to make `user_profiles_cupy` 4x1x6. CuPy can then match the 1 to `categories_cupy`'s 5, and will multiply each user profile against each item's category listing, which is exactly what we need.\n",
    "\n",
    "Since we have an extra dimension now, we'll do the sum against axis 2 instead of axis 1. We can verify that it worked because the first row will be the same as Alyx's prediction above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferences = cp.expand_dims(user_profiles_cupy, axis=1) * categories_cupy\n",
    "preferences = cp.sum(preferences, axis=2)\n",
    "\n",
    "preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to taking the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferences = cp.dot(user_profiles_cupy, categories_cupy.transpose())\n",
    "preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a predicted rating, we can scale these results by the same scale the users can use to rate items. If it's 1 - 5 stars, then we can multiply the range (5-1), and add the minimum rating (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating = 1\n",
    "max_rating = 5\n",
    "preferences = preferences * (max_rating - min_rating) + min_rating\n",
    "\n",
    "preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to bring it all together. Let's create a DataFrame to match each predicted rating to each user-item combo. Because we were careful to preserve order during the operations above, we can use [MultiIndex.from_product](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.from_product.html) in order to build a DataFrame for each user-item combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = user_profiles.index.to_series().to_array()\n",
    "category_ids = categories[\"item\"].to_array()\n",
    "predictions = cudf.MultiIndex.from_product([user_ids, category_ids], names=[\"user\", \"item\"])\n",
    "predictions = cudf.DataFrame(index = predictions).reset_index()\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use CuPy's [ravel](https://docs-cupy.chainer.org/en/stable/reference/generated/cupy.ravel.html) function to flatten our predictions and add it as a column to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"predicted_rating\"] = cp.ravel(preferences)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We now have predictions for each user-item interaction combo. We can sort the ratings for each user and recommend their top X items. There's one last important piece of the puzzle in that we don't want to recommend something the user has rated before. Let's add in the original ratings to do this.\n",
    "\n",
    "Before moving on to the next step, let's compare the predicted rating with the actual rating. How did we do? Note where the algorithm went well and where it didn't and try to come up with an explanation for why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.merge(ratings, how=\"left\")\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use [loc](https://docs.rapids.ai/api/cudf/stable/api_docs/api/cudf.DataFrame.loc.html) to locate the rows without a rating yet so we can serve recommendations to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.loc[predictions['rating'].isnull()].drop(\"rating\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wrap Up\n",
    "\n",
    "We didn't split the data into train and test because our example here is too small, so using a larger dataset is bound to introduce some interesting challenges. Now that we have a system that works with synthetic data, let's test our new knowledge on the real thing. \n",
    "\n",
    "Feeling ready? Please run the cell below to shut down the kernel before moving on to the <a href=\"1-04_content_based_real_data.ipynb\">next notebook</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"./images/DLI_Header.png\"></a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
